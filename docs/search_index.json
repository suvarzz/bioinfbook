[["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2021-04-16 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandocâ€™s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["analyis-of-new-generation-sequencing-data-in-r.html", "Chapter 2 Analyis of new generation sequencing data in R 2.1 Get fastq from SRA", " Chapter 2 Analyis of new generation sequencing data in R 2.1 Get fastq from SRA "],["get-fastq-from-sra-database.html", "Chapter 3 Get fastq from SRA database 3.1 Get fastq from SRA database", " Chapter 3 Get fastq from SRA database library(SRAdb) # SRA database dir.create(&quot;~/SRA&quot;) setwd(&quot;~/SRA&quot;) ## Create database sqlfile &lt;-&#39;SRAmetadb.sqlite&#39; # load database [~3 Gb, 60 Gb on disc!!!] if(!file.exists(&#39;SRAmetadb.sqlite&#39;)) sqlfile &lt;&lt;- getSRAdbFile() # connect database sra_con &lt;- dbConnect(SQLite(), sqlfile) ## get info for SRA from created database sraInf &lt;- getSRAinfo(&quot;SRP045534&quot;, sra_con, sraType=&quot;sra&quot;) sraInf # download SRA # get SRA using SRA info [~ 5 Gb] sapply(sraInf$run, function(x) try(getSRAfile(x, sra_con, fileType=&quot;sra&quot;), silent=TRUE)) 3.1 Get fastq from SRA database library(SRAdb) # SRA database dir.create(&quot;~/SRA&quot;) setwd(&quot;~/SRA&quot;) ## Create database sqlfile &lt;-&#39;SRAmetadb.sqlite&#39; # load database [~3 Gb, 60 Gb on disc!!!] if(!file.exists(&#39;SRAmetadb.sqlite&#39;)) sqlfile &lt;&lt;- getSRAdbFile() # connect database sra_con &lt;- dbConnect(SQLite(), sqlfile) ## get info for SRA from created database sraInf &lt;- getSRAinfo(&quot;SRP045534&quot;, sra_con, sraType=&quot;sra&quot;) sraInf # download SRA # get SRA using SRA info [~ 5 Gb] sapply(sraInf$run, function(x) try(getSRAfile(x, sra_con, fileType=&quot;sra&quot;), silent=TRUE)) ## Alignment using Rsubread library(Rsubread) # sequence alignment fastq.files &lt;- list.files(pattern = &quot;.fastq.gz$&quot;, full.names = TRUE) fastq.files # build index buildindex(basename=&quot;mm10&quot;, reference=&quot;mm10.fa&quot;) # alignment align(fastq.files, index=&quot;chr1_mm10&quot;) # parameters args(align) # check result bam.files &lt;- list.files(pattern = &quot;.BAM$&quot;, full.names = TRUE) bam.files # properties of BAM files propmapped(files=bam.files) "],["differential-expression-analysis-using-basic-r.html", "Chapter 4 Differential expression analysis using basic R 4.1 Gene expression analysis of histone deacetylase 1 (HDAC1) knockout mouse. 4.2 Sources", " Chapter 4 Differential expression analysis using basic R 4.1 Gene expression analysis of histone deacetylase 1 (HDAC1) knockout mouse. This short tutorial should help to understand the basic principal of gene expression analysis using simple dataset and nearly basic R. Affymetrix microarray Dataset: GSE5583 Paper: Mol Cell Biol 2006 Nov;26(21):7913-28. PMID: 16940178 R code: Ahmed Moustafa # Read the data into R library (RCurl) url = getURL (&quot;http://bit.ly/GSE5583_data&quot;, followlocation = TRUE) data = as.matrix(read.table (text = url, row.names = 1, header = T)) # Check the loaded dataset dim(data) # Dimension of the dataset ## [1] 12488 6 # data shows gene experssion levels in 6 samples: # rows correspond to samples (3 wild type WT and 3 knock-out KO) # columns correspond to genes ids head(data) # First few rows ## WT.GSM130365 WT.GSM130366 WT.GSM130367 KO.GSM130368 KO.GSM130369 ## 100001_at 11.5 5.6 69.1 15.7 36.0 ## 100002_at 20.5 32.4 93.3 31.8 14.4 ## 100003_at 72.4 89.0 79.2 80.5 130.1 ## 100004_at 261.0 226.2 365.1 432.0 447.3 ## 100005_at 1086.2 1555.6 1487.1 1062.2 1365.9 ## 100006_at 49.7 52.9 15.0 25.8 48.8 ## KO.GSM130370 ## 100001_at 42.0 ## 100002_at 22.9 ## 100003_at 86.7 ## 100004_at 288.1 ## 100005_at 1436.2 ## 100006_at 54.8 ################### # Exploratory plots ################### # Check the behavior of the data hist(data, col = &quot;gray&quot;, main=&quot;GSE5583 - Histogram&quot;) # Log2 transformation (why?) data2 = log2(data) # Check the behavior of the data after log-transformation hist(data2, col = &quot;gray&quot;, main=&quot;GSE5583 (log2) - Histogram&quot;) # Boxplot boxplot(data2, col=c(&quot;darkgreen&quot;, &quot;darkgreen&quot;, &quot;darkgreen&quot;, &quot;darkred&quot;, &quot;darkred&quot;, &quot;darkred&quot;), main=&quot;GSE5583 - boxplots&quot;, las=2) # Hierarchical clustering of the &quot;samples&quot; based on # the correlation coefficients of the expression values hc = hclust(as.dist(1-cor(data2))) plot(hc, main=&quot;GSE5583 - Hierarchical Clustering&quot;) ####################################### # Differential expression (DE) analysis ####################################### # Separate the two conditions into two smaller data frames wt = data2[,1:3] ko = data2[,4:6] # Compute the means of the samples of each condition wt.mean = apply(wt, 1, mean) ko.mean = apply(ko, 1, mean) head(wt.mean) ## 100001_at 100002_at 100003_at 100004_at 100005_at 100006_at ## 4.039868 5.306426 6.320360 8.120503 10.408872 5.089087 head(ko.mean) ## 100001_at 100002_at 100003_at 100004_at 100005_at 100006_at ## 4.844978 4.452076 6.597451 8.576804 10.318839 5.358071 # Just get the maximum of all the means limit = max(wt.mean, ko.mean) # Scatter plot plot(ko.mean ~ wt.mean, xlab = &quot;WT&quot;, ylab = &quot;KO&quot;, main = &quot;GSE5583 - Scatter&quot;, xlim = c(0, limit), ylim = c(0, limit)) # Diagonal line abline(0, 1, col = &quot;red&quot;) # Compute fold-change (biological significance) # Difference between the means of the conditions fold = wt.mean - ko.mean # Histogram of the fold differences hist(fold, col = &quot;gray&quot;) # Compute statistical significance (using t-test) pvalue = NULL # Empty list for the p-values tstat = NULL # Empty list of the t test statistics for(i in 1 : nrow(data)) { # For each gene : x = wt[i,] # WT of gene number i y = ko[i,] # KO of gene number i # Compute t-test between the two conditions t = t.test(x, y) # Put the current p-value in the pvalues list pvalue[i] = t$p.value # Put the current t-statistic in the tstats list tstat[i] = t$statistic } head(pvalue) ## [1] 0.5449730 0.3253745 0.3287830 0.1892376 0.6928410 0.7180077 # Histogram of p-values (-log10) hist(-log10(pvalue), col = &quot;gray&quot;) # Volcano: put the biological significance (fold-change) # and statistical significance (p-value) in one plot plot(fold, -log10(pvalue), main = &quot;GSE5583 - Volcano&quot;) fold_cutoff = 2 pvalue_cutoff = 0.01 abline(v = fold_cutoff, col = &quot;blue&quot;, lwd = 3) abline(v = -fold_cutoff, col = &quot;red&quot;, lwd = 3) abline(h = -log10(pvalue_cutoff), col = &quot;green&quot;, lwd = 3) # Screen for the genes that satisfy the filtering criteria # Fold-change filter for &quot;biological&quot; significance filter_by_fold = abs(fold) &gt;= fold_cutoff dim(data2[filter_by_fold, ]) ## [1] 210 6 # P-value filter for &quot;statistical&quot; significance filter_by_pvalue = pvalue &lt;= pvalue_cutoff dim(data2[filter_by_pvalue, ]) ## [1] 429 6 # Combined filter (both biological and statistical) filter_combined = filter_by_fold &amp; filter_by_pvalue filtered = data2[filter_combined,] dim(filtered) ## [1] 42 6 head(filtered) ## WT.GSM130365 WT.GSM130366 WT.GSM130367 KO.GSM130368 KO.GSM130369 ## 100716_at 4.852998 4.906891 5.626439 7.572890 7.791163 ## 100914_at 10.340852 9.917074 10.250062 12.248787 12.185526 ## 101368_at 9.937227 10.204693 10.385215 12.270354 12.213499 ## 101550_at 5.526695 5.439623 6.221104 2.137504 2.906891 ## 101635_f_at 7.105385 6.722466 6.943687 5.266787 4.842979 ## 101883_s_at 5.768184 6.127221 5.133399 11.564292 11.679568 ## KO.GSM130370 ## 100716_at 7.299208 ## 100914_at 12.127124 ## 101368_at 12.078184 ## 101550_at 2.035624 ## 101635_f_at 4.643856 ## 101883_s_at 11.663514 # Let&#39;s generate the volcano plot again, # highlighting the significantly differential expressed genes plot(fold, -log10(pvalue), main = &quot;GSE5583 - Volcano #2&quot;) points (fold[filter_combined], -log10(pvalue[filter_combined]), pch = 16, col = &quot;red&quot;) # Highlighting up-regulated in red and down-regulated in blue plot(fold, -log10(pvalue), main = &quot;GSE5583 - Volcano #3&quot;) points (fold[filter_combined &amp; fold &lt; 0], -log10(pvalue[filter_combined &amp; fold &lt; 0]), pch = 16, col = &quot;red&quot;) points (fold[filter_combined &amp; fold &gt; 0], -log10(pvalue[filter_combined &amp; fold &gt; 0]), pch = 16, col = &quot;blue&quot;) # Cluster the rows (genes) &amp; columns (samples) by correlation rowv = as.dendrogram(hclust(as.dist(1-cor(t(filtered))))) colv = as.dendrogram(hclust(as.dist(1-cor(filtered)))) # Generate a heatmap heatmap(filtered, Rowv=rowv, Colv=colv, cexCol=0.7) library(gplots) # Enhanced heatmap heatmap.2(filtered, Rowv=rowv, Colv=colv, cexCol=0.7, col = rev(redblue(256)), scale = &quot;row&quot;, trace=&quot;none&quot;, density.info=&quot;none&quot;) # Save the heatmap to a PDF file pdf (&quot;GSE5583_DE_Heatmap.pdf&quot;) heatmap.2(filtered, Rowv=rowv, Colv=colv, cexCol=0.7, col = rev(redblue(256)), scale = &quot;row&quot;) dev.off() # Save the DE genes to a text file write.table (filtered, &quot;GSE5583_DE.txt&quot;, sep = &quot;\\t&quot;, quote = FALSE) n = nrow(filtered) cor.table = NULL x = NULL y = NULL cor.val = NULL cor.sig = NULL for (i in 1 : (n-1)) { x_name = rownames(filtered)[i] x_exps = filtered[i, ] for (j in (i+1) : n) { y_name = rownames(filtered)[j] y_exps = filtered[j, ] output = cor.test(x_exps,y_exps) x = c(x, x_name) y = c(y, y_name) cor.val = c(cor.val, output$estimate) cor.sig = c(cor.sig, output$p.value) } } cor.table = data.frame (x, y, cor.val, cor.sig) dim(cor.table) ## [1] 861 4 head(cor.table) ## x y cor.val cor.sig ## 1 100716_at 100914_at 0.9732295 0.0010653980 ## 2 100716_at 101368_at 0.9897688 0.0001564799 ## 3 100716_at 101550_at -0.9060431 0.0128271221 ## 4 100716_at 101635_f_at -0.9433403 0.0047245418 ## 5 100716_at 101883_s_at 0.9508680 0.0035616301 ## 6 100716_at 102712_at 0.9676037 0.0015572795 sig_cutoff = 0.001 cor.filtered = subset (cor.table, cor.sig &lt; sig_cutoff) dim(cor.filtered) ## [1] 314 4 head(cor.filtered) ## x y cor.val cor.sig ## 2 100716_at 101368_at 0.9897688 1.564799e-04 ## 8 100716_at 103088_at -0.9761495 8.464861e-04 ## 10 100716_at 103299_at -0.9991089 1.190632e-06 ## 14 100716_at 104700_at -0.9792543 6.411095e-04 ## 15 100716_at 160172_at 0.9833552 4.132702e-04 ## 16 100716_at 160943_at 0.9814703 5.118449e-04 4.2 Sources Ahmed Moustafa githab "],["genome-wide-associated-studies-gwas.html", "Chapter 5 Genome Wide Associated Studies (GWAS)\" 5.1 SNP analysis using SNPasoc R package 5.2 GWAS using PLINK", " Chapter 5 Genome Wide Associated Studies (GWAS)\" 5.1 SNP analysis using SNPasoc R package Example demonstrate an association test for an illness for one single SNP. install.packages(&quot;SNPassoc&quot;) library(&quot;SNPassoc&quot;) data(SNPs) head(SNPs) head(SNPs.info.pos) # select 6-40 SNP and create SNP object mySNP &lt;- setupSNP(SNPs, 6:40, sep=&quot;&quot;) # casco - 1 for case, 0 for control) mySNP # association test res &lt;- association(casco~sex+snp10001+blood.pre, data = mySNP, model.interaction = c(&quot;dominant&quot;,&quot;codominant&quot;)) res 0 - control sample size % - percent for each variant 1 - case sample size % - percent for each varian OR - odd ratio lower/upper - 95% confidence interval for odd ratio p-value of likelihood ratio test AIC - Akaike Information Criterion # association scan for SNPs - separately for all models res &lt;- WGassociation(protein, data = mySNP, model = &#39;all&#39;) # same formula as protein~1, # p-values for dominant model dominant(res) # p-values for recessive model recessive(res) # complete statistics WGstats(res) summary(res) # Plot p-values for all models plot(res) # whole genome association - one log model resHapMap &lt;- WGassociation(protein, data= mySNP, model=&#39;log&#39;) plot(resHapMap) Another examplw for all genome association # two population groups (CEU and YRI), 60 samples for each group data(HapMap) str(HapMap) str(HapMap.SNPs.pos) # SNP class object myHapMap &lt;- setupSNP(HapMap, colSNPs=3:9307, sort=TRUE, info=HapMap.SNPs.pos, sep=&quot;&quot;) # association for dominant model myHapMapres &lt;- WGassociation(group, data= myHapMap, model=&quot;dominant&quot;) head(myHapMapres) print(myHapMapres) # plot association for all chromosomes plot(myHapMapres, whole=TRUE) 5.2 GWAS using PLINK The PLINK format of the GWAS data consists of two separate files, one containing the SNP information (.ped)and the other containing the mapping information (.map). For dependence analysis, it can be combined with the phenotype data separately. "],["hi-c-workflow.html", "Chapter 6 Hi-C workflow 6.1 Using straw tool to extract contact matrix from .hic files 6.2 HiC-Pro pipeline 6.3 multiHiC compare for compare of 2 Hi-C datasets (Rao et al.Â 2017) 6.4 Joint normalization of Hi-C 6.5 Difference detection", " Chapter 6 Hi-C workflow Workflow from Stansfield et al., Current Protocols in Bioinformatics, 2019 Hi-C workflow steps: 1. mapping reads 2. assigning fragments 3. filtering fragments 4. binning 5. bin-level filtering 6. balancing (normalization) of individual matrices Paired-end reads of Hi-C experiments are mapped using the single-end mode to map each read (of the pair) independently. The theoretical maximum resolution of Hi-C sequencing is set by the restriction enzyme used to cut the DNA. However, most Hi-C datasets are not sequenced deeply enough to reach this theoretical maximum, and typically one of a few fixed-size resolutions are chosen for analyzing the data, including 1 Mb, 100 kb, 50 kb, 40 kb, 20 kb, 10 kb, and 5 kb. Two of the more popular pipelines for aligning Hi-C data are juicer (Durand, Shamim, &amp; Aiden, 2016) and HiC-Pro (Servant et al., 2015). juicer takes fastq files and aligns the data into .hic sparse contact maps. Alignment is based on BWA. Contact maps can be extracted from .hic files using juicer or the command line tool straw. 6.1 Using straw tool to extract contact matrix from .hic files &lt;NONE/VC/VC_SQRT/KR&gt; &lt;hicFile(s)&gt; &lt;chr1&gt;[:x1:x2] &lt;chr2&gt;[:y1:y2] &lt;BP/FRAG&gt; &lt;binsize&gt; VC - vanilla coverage normalization VC_SQRT - square root of vanilla coverage normalization KR - Knight-Ruiz (KR) normalization BP/FRAG - base pare or fragment size. Typically we use BP. mkdir ~/GEO cd ~/GEO # download .hic file [9 Gb] wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE63nnn/GSE63525/suppl/GSE63525_K562_combined_30.hic # extract raw matrix for 22 chromosome at 500-kb resolution straw NONE GSE63525_K562_combined_30.hic 22 22 BP 500000 &gt; K562.chHCT116_r22.500 kb.txt txt file is in the sparse upper-triangular matrix format, containing 3 columns: 1. start of interaction 2. end of interaction 3. frequency (IF) 6.2 HiC-Pro pipeline Output 2 files (.matrix and .bed): * The .matrix is plain-text 3-column sparse upper-triangular matrix with the columns \\(bin_i\\) \\(bin_j\\) and \\(counts_ij\\). * The .bed file contains the genomic coordinates for each \\(bin_i\\) and \\(bin_j\\). sparse2full - convert sparse upper-triangular matrix to full contact matrix. hicpro2bedpe - convert alignments by HiC-Pro into BEDPE format. hicpro2bedpe - input .matrix and .bed and convert into sparse upper-triangular matrix. 6.3 multiHiC compare for compare of 2 Hi-C datasets (Rao et al.Â 2017) mkdir ~/GEO cd ~/GEO # download .hic files from wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2795nnn/GSM2795535/suppl/GSM2795535_Rao-2017-HIC001_30.hic wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2795nnn/GSM2795536/suppl/GSM2795536_Rao-2017-HIC002_30.hic wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2809nnn/GSM2809539/suppl/GSM2809539_Rao-2017-HIC008_30.hic wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2809nnn/GSM2809540/suppl/GSM2809540_Rao-2017-HIC009_30.hic # convert .hic to sparse contact matrix for each of 22 chromosomes for i in {1,2,8,9} do mkdir HIC00${i} for j in {1..22} do straw NONE *_Rao-2017-HIC00${i}_30.hic $j $j BP 100000 &gt; HIC00${i}/HIC00${i}.NONE.chr${j}.100000.txt done done library(readr) library(data.table) library(dplyr) library(edgeR) library(BiocParallel) library(HiCcompare) library(multiHiCcompare) options(scipen = 10) # output fixed numbers # Set up parameters for reading in data chr &lt;- paste0(&#39;chr&#39;, c(1:22)) # Chromosome names samples &lt;- paste0(&#39;HIC00&#39;, c(1,2,8,9)) # Sample names res &lt;- 100000 # Data resolution # Read data sample_list &lt;- list() chr_list &lt;- list() wd &lt;- &#39;/home/suvar/GEO/&#39; for(j in 1:length(samples)) { for (i in 1:length(chr)) { chr_list[[i]] &lt;- read_tsv(paste0(wd, samples[j], &#39;/&#39;, samples[j], &#39;.NONE.&#39;, chr[i], &#39;.&#39;, res, &#39;.txt&#39;), col_names = FALSE) %&gt;% as.data.table() # Add column indicating the chromosome chr_list[[i]] &lt;- cbind(i, chr_list[[i]]) colnames(chr_list[[i]]) &lt;- c(&#39;chr&#39;, &#39;region1&#39;, &#39;region2&#39;, &#39;IF&#39;) } sample_list[[j]] &lt;- chr_list chr_list &lt;- list() } # Collapse separate chromosome lists into one table per sample sample_list &lt;- lapply(sample_list, rbindlist) sample_list[[1]] 6.4 Joint normalization of Hi-C library(pander) # Create a Hicexp object for use by multiHiCcompare (~10 min) # Four objects are assigned into two groups rao2017 &lt;- make_hicexp(data_list = sample_list, groups = c(1,1,2,2)) rao2017 # class(rao2017) # view the IF information hic_table(rao2017) # MD plots before normalization MD_hicexp(rao2017, plot.chr = 1, plot.loess = TRUE) # Normalize (~2 min) rao2017 &lt;- fastlo(rao2017) # cyclic loesss normalisation is also available # Plot normalization results MD_hicexp(rao2017, plot.chr = 1, plot.loess = TRUE) # Print normalized IFs pander::pandoc.table(head(hic_table(rao2017))) library(BiocParallel) # Check how many cores are available numCores &lt;- parallel::detectCores() # Set the number of cores at least one less than the total number if(Sys.info()[&#39;sysname&#39;] == &#39;Windows&#39;) { # Windows settings register(SnowParam(workers = numCores-1), default = TRUE) }else { # Unix settings register(MulticoreParam(workers = numCores-1), default = TRUE) } 6.5 Difference detection # Perform exact test (~10 min) # May use &quot;parallel = TRUE&quot; option to speed up computations rao2017 &lt;- hic_exactTest(rao2017, parallel = TRUE) # Plot a composite MD plot with the results of a comparison MD_composite(rao2017,plot.chr = 1) # Print results as a data frame pander::pandoc.table(head(results(rao2017))) # Save the Hicexp object save(rao2017, file = paste0(wd,&#39;rao2017.RDA&#39;)) # To start the downstream analysis # without re-running multiHiCcompare load the saved file # load(paste0(wd,&#39;rao2017.RDA&#39;)) "]]
